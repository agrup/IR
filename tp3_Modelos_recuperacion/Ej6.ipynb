{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de Recuperaciòn de Informaciòn (y evaluaciòn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la colecci´on provista por el equipo docente1\n",
    ", cuya estructura es la siguiente:\n",
    "    \n",
    "vocabulary.txt → [id termino, idf, t´ermino]\n",
    "\n",
    "documentVectors.txt → [id doc, lista(id terminos)]\n",
    "\n",
    "queries.txt → [id query, lista(id terminos)]\n",
    "\n",
    "relevants.txt → [id query, listarelevantes (id doc)]\n",
    "\n",
    "informationNeeds.txt → [id in, texto libre]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Calcule los conjuntos de respuestas usando el modelo booleano y el modelo vectorial (asuma en todos\n",
    "los casos T F = 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir\n",
    "import math\n",
    "from modulos.tokenizer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_idf(corpus_count,doc_freq):\n",
    "    if(doc_freq !=0):\n",
    "        return math.log(corpus_count/doc_freq,2)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexer(dirname):\n",
    "        files = listdir(dirname)\n",
    "        vocabulary={}\n",
    "        document_vector={}\n",
    "        id_voc=0\n",
    "        vocavulary_result=[]\n",
    "        docs_count=len(files)\n",
    "        for file in files:\n",
    "            lines = open(dirname+'/'+file,'r',errors = 'ignore').readlines()\n",
    "            docu_voc=[]\n",
    "            tokens=tokenizar(lines)\n",
    "            #docs_count+=1\n",
    "            for token in tokens:\n",
    "                if token not in vocabulary:\n",
    "                    vocabulary[token]=(id_voc,1)\n",
    "                    docu_voc.append(id_voc)\n",
    "                    id_voc =id_voc+1\n",
    "                    #print(token,docu_voc)\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "                    id,doc_freq = vocabulary[token]\n",
    "                    \n",
    "                    #print(id,docu_voc)\n",
    "                    if id not in docu_voc:\n",
    "                       \n",
    "                        doc_freq = doc_freq+1\n",
    "                        docu_voc.append(id)\n",
    "                        \n",
    "                    vocabulary[token]=(id,doc_freq)\n",
    "                    \n",
    "            document_vector[file]=docu_voc\n",
    "        #print(document_vector)\n",
    "        #print(vocabulary)\n",
    "        for termn in vocabulary.items():\n",
    "            #print(termn[1][1],docs_count)\n",
    "            vocavulary_result.append([termn[1][0],calc_idf(docs_count,termn[1][1]),termn[0]])\n",
    "        #print (vocavulary_result)\n",
    "        return (vocavulary_result,document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary,documents=  indexer('/home/agu/Unlu/IR/coleccion_2018_final/')\n",
    "#print(vocabulary)\n",
    "#print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3.1043366598147353, 'ingenios'], [2, 3.1043366598147353, 'coleccion'], [3, 0.0, 'de'], [4, 2.2563397532597858, 'vistas'], [5, 0.9505313237357003, 'principales'], [6, 4.256339753259786, 'azucar'], [7, 0.0, 'la'], [8, 1.0339473319233377, 'isla'], [9, 2.2563397532597858, 'cuba'], [10, 2.7258250365610057, 'edicion'], [11, 1.3818706353436445, 'lujo'], [12, 0.0, 'el'], [13, 1.8115549105868898, 'texto'], [14, 4.104336659814735, 'redactado'], [15, 0.0, 'por'], [16, 0.6580804299251717, 'justo'], [17, 5.841302253980943, 'cantero'], [18, 1.6189098326444942, 'gentil'], [19, 0.19744606420621716, 'hombre']]\n"
     ]
    }
   ],
   "source": [
    "#voc = (list(get_vocabulary(\"ejemploRibeiro/vocabulary.txt\", True)))\n",
    "#doc = (get_document_vector(\"ejemploRibeiro/documentVector.txt\", True))\n",
    "voc = vocabulary\n",
    "vocabulary_list=list(map(itemgetter(2), voc))\n",
    "#doc = documents\n",
    "#doc_bool= to_boolean(doc,voc)\n",
    "print (voc[1:20])\n",
    "#print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query(query,vocabulary_list):\n",
    "    \n",
    "    query_result=[]\n",
    "    querys = query.split()\n",
    "    query_terms=[]\n",
    "    terms_count={}\n",
    "    query_freq=[]\n",
    "    for term  in querys:\n",
    "        if term not in query_terms:\n",
    "            query_terms.append(term)\n",
    "            terms_count[term]=1\n",
    "            if term in vocabulary_list:\n",
    "                query_result.append(vocabulary_list.index(term))  \n",
    "        else:\n",
    "            terms_count[term]+=1\n",
    "    for term,count in terms_count.items():\n",
    "        query_freq.append(count)\n",
    "    return query_result, query_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101491, 5215, 77383]\n",
      "[1, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "query,query_freq =get_query(\"hello agustin dog dog dog\",vocabulary_list)\n",
    "print(query)\n",
    "query_w =[]\n",
    "print (query_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['42323-8.txt', '39312-8.txt', '14307-8.txt', '44120-8.txt', '26028-8.txt', '18723-8.txt', '45151-8.txt', '27757-8.txt', '15421-8.txt', '27167-8.txt', '41884-8.txt', '19643-8.txt', '13216-8.txt', '11669-8.txt', '15633-8.txt', '13458-8.txt', '28904-8.txt', '45180-8.txt', '28967-8.txt', '20401-8.txt', '19106-8.txt', '30053-8.txt', '40358-8.txt']\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "query_documents=[]\n",
    "for term in query:\n",
    "\n",
    "    #print(term)\n",
    "    \n",
    "    for document, values in documents.items():\n",
    "        #print(values)\n",
    "        if term in values:\n",
    "            if document not in query_documents:   \n",
    "                query_documents.append(document)\n",
    "\n",
    "print(query_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normal(list_term,vocabulary):\n",
    "    query_normal=0\n",
    "    for term in list_term:\n",
    "        val=(vocabulary[term][1])\n",
    "        query_normal+=float(val)**2\n",
    "    query_normal=math.sqrt(query_normal)\n",
    "    #print(query_normal,\"fnc\")\n",
    "    return(query_normal)\n",
    "def get_query_w(index, query_w,idf):\n",
    "    #print(0,5*(query_w[index]/max(query_w))*idf,\"qqqqqq\")\n",
    "    return 0.5+ 0.5*(query_w[index]/max(query_w))*idf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101491, 5215, 77383]\n",
      "Boolean Result\n",
      "42323-8.txt\n",
      "39312-8.txt\n",
      "14307-8.txt\n",
      "44120-8.txt\n",
      "26028-8.txt\n",
      "18723-8.txt\n",
      "45151-8.txt\n",
      "27757-8.txt\n",
      "15421-8.txt\n",
      "27167-8.txt\n",
      "41884-8.txt\n",
      "19643-8.txt\n",
      "13216-8.txt\n",
      "11669-8.txt\n",
      "15633-8.txt\n",
      "13458-8.txt\n",
      "28904-8.txt\n",
      "45180-8.txt\n",
      "28967-8.txt\n",
      "20401-8.txt\n",
      "19106-8.txt\n",
      "30053-8.txt\n",
      "40358-8.txt\n",
      "------------------------\n",
      "Vectorial Result\n",
      "('30053-8.txt', 0.36050985485287856)\n",
      "('40358-8.txt', 0.36050985485287856)\n",
      "('42323-8.txt', 0.16871519835483872)\n",
      "('39312-8.txt', 0.09877884310590605)\n",
      "('14307-8.txt', 0.09877884310590605)\n",
      "('44120-8.txt', 0.09877884310590605)\n",
      "('26028-8.txt', 0.09877884310590605)\n",
      "('18723-8.txt', 0.09877884310590605)\n",
      "('45151-8.txt', 0.09877884310590605)\n",
      "('27757-8.txt', 0.09877884310590605)\n",
      "('15421-8.txt', 0.09877884310590605)\n",
      "('27167-8.txt', 0.09877884310590605)\n",
      "('41884-8.txt', 0.09877884310590605)\n",
      "('19643-8.txt', 0.09877884310590605)\n",
      "('13216-8.txt', 0.09877884310590605)\n",
      "('11669-8.txt', 0.09877884310590605)\n",
      "('15633-8.txt', 0.09877884310590605)\n",
      "('13458-8.txt', 0.09877884310590605)\n",
      "('28904-8.txt', 0.09877884310590605)\n",
      "('45180-8.txt', 0.09877884310590605)\n",
      "('28967-8.txt', 0.09877884310590605)\n",
      "('20401-8.txt', 0.09877884310590605)\n",
      "('19106-8.txt', 0.09877884310590605)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "result=[]\n",
    "print(query)\n",
    "#print(get_normal(query,voc))\n",
    "query_normal=get_normal(query,voc)\n",
    "\n",
    "result_q=[]\n",
    "\n",
    "terms_isin_documents={}\n",
    "\n",
    "for term in query:\n",
    "    if voc[term][1] > 0:\n",
    "        query_document=[]\n",
    "        for document, values in documents.items():\n",
    "            #docu, value = doc\n",
    "            if term in values:\n",
    "                if (document not in [ids for ids, _ in result_q]):\n",
    "                    query_document.append((document,voc[term][1]))\n",
    "\n",
    "            if(term in terms_isin_documents.keys()):\n",
    "                terms_isin_documents[str(term)].extend(query_document)     \n",
    "            else:\n",
    "                if len(query_document)>0:\n",
    "                    terms_isin_documents[str(term)]=query_document\n",
    "        result_q.extend(query_document)\n",
    "#print(\"query\",query_document) \n",
    "result.append((\"query\",result_q))\n",
    "\n",
    "print(\"Boolean Result\")\n",
    "for doc,_ in result_q:\n",
    "    print(doc)\n",
    "#print(result_q)\n",
    "query_vector=[]\n",
    "for index,(key,value) in enumerate(terms_isin_documents.items()):\n",
    "\n",
    "    idf=float(voc[int(key)][1])\n",
    "    tf_maxtf= get_query_w(index,query_freq,float(voc[int(key)][1]))\n",
    "    #query_vector.append(float(voc[int(key)][1]))\n",
    "    #print(tf_maxtf)\n",
    "    query_vector.append(tf_maxtf)\n",
    "\n",
    "\n",
    "vector_result=[]\n",
    "#print(query_vector,\"qv\")\n",
    "for name,idf in result_q:\n",
    "    #print(result_q)\n",
    "    vect_sim =[]\n",
    "    sim=0\n",
    "    #value son los documentos que contienen los terminos\n",
    "    #print(terms_isin_documents.items())\n",
    "    for key,value in terms_isin_documents.items():\n",
    "        if (name in [val[0] for val in value]):\n",
    "            vect_sim.append(float(idf))\n",
    "        else:\n",
    "            vect_sim.append(0)\n",
    "    vector_result.append((name,vect_sim))\n",
    "print(\"------------------------\")\n",
    "print(\"Vectorial Result\")\n",
    "#print(vector_result)\n",
    "list_response=[]\n",
    "#print(query_normal)\n",
    "for doc,vec in vector_result:\n",
    "    #r=np.array(r)\n",
    "    q=0\n",
    "\n",
    "    for idf in vec:\n",
    "        q+=idf**2\n",
    "    q = math.sqrt(q)\n",
    "    q = (np.dot(vec,query_vector)) /(query_normal*q)\n",
    "    list_response.append((doc,q))\n",
    "\n",
    "\n",
    "(list_response.sort(key=itemgetter(1),reverse=True))\n",
    "\n",
    "for doc in list_response:\n",
    "    print(doc)\n",
    "print(\"-----------------\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
